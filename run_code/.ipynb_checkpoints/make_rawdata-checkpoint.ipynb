{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea7a0d6-d8d6-4dc4-bdc1-ab1b4af2bb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class varDataset:\n",
    "\n",
    "    r\"\"\"\n",
    "    Creates an instance of dataset object based on requested files & variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Directory containing files for concatenation.\n",
    "    varname : str\n",
    "        Name of variable in files.\n",
    "    climo : ndarray\n",
    "\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    level : float\n",
    "        If file contains data for multiple levels\n",
    "    climoyears : tuple\n",
    "        (start year, end year) to slice data\n",
    "    latbounds : tuple\n",
    "        (south lat, north lat) to slice data\n",
    "    lonbounds : tuple)\n",
    "        (west lon, east lon) to slice data\n",
    "    eofs : ndarray\n",
    "        Provided eofs\n",
    "    max_eofs : int\n",
    "        How many modes to retain from the EOF decomposition.\n",
    "    time_window : int\n",
    "        Used for running_mean, days.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dataset : object\n",
    "        An instance of Dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,varlabel,datapath,varname,**kwargs):\n",
    "\n",
    "        self.varlabel = varlabel\n",
    "        self.datapath = datapath\n",
    "        self.varname = varname\n",
    "        # kwargs\n",
    "        self.level = kwargs.pop('level',None)\n",
    "        self.climoyears = kwargs.pop('climoyears',None)\n",
    "        self.datebounds = kwargs.pop('datebounds',('1/1','12/31'))\n",
    "        season0 = kwargs.pop('season0',True)\n",
    "        self.latbounds = kwargs.pop('latbounds',None)\n",
    "        self.lonbounds = kwargs.pop('lonbounds',None)\n",
    "        self.time_window = kwargs.pop('time_window',None)\n",
    "        self.climo = kwargs.pop('climo',None)\n",
    "        self.landmask = kwargs.pop('landmask',False)\n",
    "        self.smoother = kwargs.pop('smoother',None)\n",
    "        self.coarsegrain = kwargs.pop('coarsegrain',None)\n",
    "        self.attrs = {}\n",
    "        print(varlabel)\n",
    "        print(datapath)\n",
    "        print(varname)\n",
    "        # print(kwargs)\n",
    "        # Concatenate all files into one dataset\n",
    "        filenames = sorted([join(datapath, f) for f in listdir(datapath) \\\n",
    "                     if isfile(join(datapath, f)) and f.endswith('.nc')])\n",
    "\n",
    "        ds = self.get_ds(filenames)\n",
    "        ds\n",
    "        if self.climoyears is None:\n",
    "            self.climoyears = (min(ds['time']).year,max(ds['time']).year)\n",
    "        climo_set = np.array([(i.year>=min(self.climoyears)) & (i.year<=max(self.climoyears)) for i in ds['time']])\n",
    "        print(self.climoyears)\n",
    "        # print(ds['time'])\n",
    "        # print(climo_set)\n",
    "        ds['time'] = ds['time'][climo_set]\n",
    "        ds['var'] = ds['var'][climo_set]\n",
    "\n",
    "        self.lat = ds['lat'][self.domain]\n",
    "        self.lon = ds['lon'][self.domain]\n",
    "        self.latgrid = ds['lat']\n",
    "        self.longrid = ds['lon']\n",
    "\n",
    "        # Data manipulation\n",
    "        if self.climo is None:\n",
    "            print('getting climo, Line 119 dataset')\n",
    "            self.climo = get_climo(ds['var'],ds['time'],self.climoyears)\n",
    "        else:\n",
    "            print('self.climo is not None')\n",
    "            self.climo = np.array([self.flatten(i) for i in self.climo])\n",
    "            self.climo[abs(self.climo)>1e29]=np.nan\n",
    "\n",
    "        if self.varname == 'anomaly':\n",
    "            print('varname has anomaly')\n",
    "            anomaly = copy.copy(ds['var'])\n",
    "        else:\n",
    "            print('getting anomaly, Line 127 dataset')\n",
    "            anomaly = get_anomaly(ds['var'],ds['time'],self.climo)\n",
    "\n",
    "        if self.time_window is None:\n",
    "            print('no time_window!!!!')\n",
    "            self.running_mean = anomaly\n",
    "        else:\n",
    "            print('getting running mean!!!!')\n",
    "            self.running_mean = get_running_mean(anomaly,self.time_window)[self.time_window:]\n",
    "            ds['time'] = ds['time'][self.time_window:]\n",
    "\n",
    "        if season0:\n",
    "            datewhere = np.where(list(map(self._date_range_test,ds['time'])) & \\\n",
    "                                 (ds['time']>=dt.strptime(f'{min(self.climoyears)}/{self.datebounds[0]}','%Y/%m/%d')) & \\\n",
    "                                 (ds['time']<=dt.strptime(f'{max(self.climoyears)}/{self.datebounds[1]}','%Y/%m/%d')))[0]\n",
    "            print(datewhere)\n",
    "        else:\n",
    "            datewhere = np.where(list(map(self._date_range_test,ds['time'])))[0]\n",
    "\n",
    "        self.time = ds['time'][datewhere]\n",
    "        if isinstance(self.time,np.ma.MaskedArray):\n",
    "            self.time = self.time.data\n",
    "        self.running_mean = self.running_mean[datewhere]\n",
    "\n",
    "        self.climo_stdev = np.nanstd(self.running_mean)\n",
    "        self.climo_mean = np.nanmean(self.running_mean)\n",
    "        print('we are done here')\n",
    "        \n",
    "\n",
    "    def get_ds(self,filenames):\n",
    "\n",
    "        ds = {}\n",
    "        print('--> Starting to gather data')\n",
    "        timer_start = dt.now()\n",
    "        for prog,fname in enumerate(filenames):\n",
    "            print(f'getting {fname}')\n",
    "            ds0 = nc.Dataset(fname)\n",
    "            # print(ds0['time'])\n",
    "            print(self.coarsegrain)\n",
    "\n",
    "            if 'climo' in ds0.variables:\n",
    "                self.climo = ds0['climo']\n",
    "\n",
    "            lat_name = ([s for s in ds0.variables.keys() if 'lat' in s]+[None])[0]\n",
    "            lon_name = ([s for s in ds0.variables.keys() if 'lon' in s]+[None])[0]\n",
    "            lev_name = ([s for s in ds0.variables.keys() if 'lev' in s or 'lv_' in s]+[None])[0]\n",
    "            time_name = ([s for s in ds0.variables.keys() if 'time' in s]+[None])[0]\n",
    "            var_name = self.varname\n",
    "\n",
    "            try:\n",
    "                self.attrs['long_name']=ds0[var_name].long_name\n",
    "            except:\n",
    "                self.attrs['long_name']=None\n",
    "            try:\n",
    "                self.attrs['units']=ds0[var_name].units\n",
    "            except:\n",
    "                self.attrs['units']=None\n",
    "\n",
    "            ds['lat']=ds0[lat_name][:]\n",
    "            ds['lon']=ds0[lon_name][:]\n",
    "            print(ds['lat'])\n",
    "            print(ds['lon'])\n",
    "            if len(ds['lat'].shape)==1:\n",
    "                ds['lon'],ds['lat'] = np.meshgrid(ds['lon'],ds['lat'])\n",
    "            if lev_name is not None:\n",
    "                if self.level is None:\n",
    "                    ilev = 0\n",
    "                else:\n",
    "                    ilev = list(ds0[lev_name]).index(self.level)\n",
    "                    self.attrs['level']=self.level\n",
    "                ds['lev']=ds0[lev_name][:][ilev]\n",
    "            try:\n",
    "                timeunits = ds0[time_name].Units\n",
    "            except:\n",
    "                timeunits = ds0[time_name].units\n",
    "            if timeunits=='Daily':\n",
    "                yr = int(fname[-7:-3])\n",
    "                tmp = np.array([dt(yr,1,1)+timedelta(days=i-1) for i in ds0[time_name][:]])\n",
    "            else:\n",
    "                tmp = nc.num2date(ds0[time_name][:],timeunits,\\\n",
    "                                  only_use_cftime_datetimes=False,only_use_python_datetimes=True)\n",
    "                # print(tmp)\n",
    "            perday = int(86400/(tmp[1]-tmp[0]).total_seconds())\n",
    "            # print(perday)\n",
    "            tmp = tmp[::perday]\n",
    "\n",
    "            if prog==0:\n",
    "                ds['time'] = tmp\n",
    "            else:\n",
    "                ds['time'] = np.append(ds['time'],tmp)\n",
    "\n",
    "            if len(ds0[var_name].shape)>3:\n",
    "                newdata = ds0[var_name][:,ilev].squeeze()\n",
    "            elif len(ds0[var_name].shape)<3:\n",
    "                newdata = ds0[var_name][None,:]\n",
    "            else:\n",
    "                newdata = ds0[var_name][:]\n",
    "\n",
    "            if perday != 1:\n",
    "                newdata = np.apply_along_axis(lambda x: np.convolve(x,np.ones(perday)/perday, mode='valid')[::4],\\\n",
    "                                              axis=0, arr=newdata)\n",
    "\n",
    "            if self.smoother is not None:\n",
    "                newdata = gfilt(newdata,[0]+[self.smoother]*len(newdata.shape[1:]))\n",
    "            print('rght before coarsegrain')\n",
    "            print(self.coarsegrain)\n",
    "            if self.coarsegrain is not None:\n",
    "                print('coarsegraining')\n",
    "                new_lats = np.arange(90,-91,-self.coarsegrain)\n",
    "                new_lons = np.arange(0,360,self.coarsegrain)\n",
    "                newdata = np.array([interp(ds['lat'], ds['lon'], new_lats, new_lons, var_day) for var_day in newdata])\n",
    "                # lonres = abs(statistics.mode(np.gradient(ds['lon'].data)[1].flatten()))\n",
    "                # latres = abs(statistics.mode(np.gradient(ds['lat'].data)[0].flatten()))\n",
    "                # lonbin = int(self.coarsegrain/lonres)\n",
    "                # latbin = int(self.coarsegrain/latres)\n",
    "                # new_lats = ds['lat'][::latbin,::lonbin]\n",
    "                # new_lons = ds['lon'][::latbin,::lonbin]\n",
    "                # newdata = newdata[:,::latbin,::lonbin]\n",
    "                ds['lat']=new_lats\n",
    "                ds['lon']=new_lons\n",
    "            # Move this here so that the interpolation works\n",
    "            ds['lon']=ds['lon'][:]%360\n",
    "            self.mapgrid = np.ones(newdata.shape[1:])*np.nan\n",
    "\n",
    "            if self.latbounds is None:\n",
    "                lim_S = np.amin(ds['lat'])\n",
    "                lim_N = np.amax(ds['lat'])\n",
    "            else:\n",
    "                lim_S = min(self.latbounds)\n",
    "                lim_N = max(self.latbounds)\n",
    "            if self.lonbounds is None:\n",
    "                lim_W = np.amin(ds['lon'])\n",
    "                lim_E = np.amax(ds['lon'])\n",
    "            else:\n",
    "                lim_W = min(self.lonbounds)\n",
    "                lim_E = max(self.lonbounds)\n",
    "            zmask = np.ones(self.mapgrid.shape,dtype=bool)\n",
    "            if self.landmask:\n",
    "                print('maksing')\n",
    "                lon_shift = ds['lon'].copy()\n",
    "                lon_shift[ds['lon']>180] = ds['lon'][ds['lon']>180]-360\n",
    "                zmask = zmask*globe.is_land(ds['lat'],lon_shift)\n",
    "\n",
    "            self.domain = np.where((ds['lat']>=lim_S) & \\\n",
    "                              (ds['lat']<=lim_N) & \\\n",
    "                              (ds['lon']>=lim_W) & \\\n",
    "                              (ds['lon']<=lim_E) & \\\n",
    "                              zmask)\n",
    "\n",
    "            newdata = np.array([n[self.domain] for n in newdata])\n",
    "            newdata[abs(newdata)>1e29]=np.nan\n",
    "\n",
    "            if prog==0:\n",
    "                ds['var'] = newdata\n",
    "            else:\n",
    "                ds['var'] = np.append(ds['var'],newdata,axis=0)\n",
    "        #     update_progress('Gathering data',(prog+1)/len(filenames))\n",
    "        # print('--> Completed gathering data (%.1f seconds)' \\\n",
    "        #       % (dt.now()-timer_start).total_seconds())\n",
    "        return ds\n",
    "    def _date_range_test(self,t):\n",
    "        t_min,t_max = [dt.strptime(i,'%m/%d') for i in self.datebounds]\n",
    "        t_max += timedelta(days=1,seconds=-1)\n",
    "        if t_min<t_max:\n",
    "            test1 = (t>=t_min.replace(year=t.year))\n",
    "            test2 = (t<=t_max.replace(year=t.year))\n",
    "            print(test1,test2)\n",
    "            return test1 & test2\n",
    "        else:\n",
    "            test1 = (t_min.replace(year=t.year)<=t<dt(t.year+1,1,1))\n",
    "            test2 = (dt(t.year,1,1)<=t<=t_max.replace(year=t.year))\n",
    "            return test1 | test2\n",
    "    def regrid(self,a):\n",
    "        # Take 1-d vector of same length as domain\n",
    "        # and transform to original grid\n",
    "        b = self.mapgrid.copy()\n",
    "        b[self.domain] = a\n",
    "        return b\n",
    "        \n",
    "    def save_to_netcdf(self,path,segmentby=None):\n",
    "\n",
    "        data_seg = {}\n",
    "        if segmentby in (None,'all'):\n",
    "            running_mean = self.running_mean\n",
    "            time = self.time\n",
    "            data_seg['all'] = {'running_mean':running_mean,'time':time}\n",
    "\n",
    "        elif segmentby == 'year':\n",
    "            years = np.array([t.year for t in self.time])\n",
    "            for yr in range(min(years),max(years)+1):\n",
    "                idata = np.where(years==yr)\n",
    "                running_mean = self.running_mean[idata]\n",
    "                time = self.time[idata]\n",
    "                data_seg[yr] = {'running_mean':running_mean,'time':time}\n",
    "\n",
    "        try:\n",
    "            attrs = copy.copy(self.attrs)\n",
    "        except:\n",
    "            attrs = {}\n",
    "\n",
    "        for K,V in data_seg.items():\n",
    "            Vmap = list(map(self.regrid,V['running_mean']))\n",
    "            Cmap = list(map(self.regrid,self.climo))\n",
    "            vardict = {\"anomaly\": {'dims':(\"time\",\"lat\",\"lon\"),\n",
    "                                   'data':Vmap,\n",
    "                                   'attrs':attrs},\n",
    "                       \"climo\": {'dims':(\"doy\",\"lat\",\"lon\"),\n",
    "                                 'data':Cmap,\n",
    "                                 'attrs':attrs}\n",
    "                       }\n",
    "            coords={\n",
    "                \"lon\": {'dims':('lon',),'data':self.longrid[0,:],\n",
    "                        'attrs':{'long_name':'longitude','units':'degrees_east'}},\n",
    "                \"lat\": {'dims':('lat',),'data':self.latgrid[:,0],\n",
    "                        'attrs':{'long_name':'latitude','units':'degrees_north'}},\n",
    "                \"time\": {'dims':('time',),'data':V['time'],\n",
    "                         'attrs':{'long_name':'time'}},\n",
    "                \"doy\": {'dims':('doy',),'data':np.arange(1,366),\n",
    "                        'attrs':{'long_name':'day of the year'}},\n",
    "            }\n",
    "            print(f'outputting {self.varlabel} to netcdf, Line 545 dataset.py')\n",
    "            save_ncds(vardict,coords,filename=join(path,f'{self.varlabel}.{K}.nc'))\n",
    "    def flatten(self,a):\n",
    "        # Take n-d array and flatten\n",
    "        b = a[self.domain]\n",
    "        return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e404aae3-f4e7-40d0-85bb-0ec6e54865b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime as dt,timedelta\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdee79c-1b73-4df5-a6a6-46abf81f1b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c06ddce-1d3f-42b7-99cb-273278dfe2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac71cc4-4ef6-4b17-8c2e-b64a4e40db8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lib\n",
    "# from lib import driver\n",
    "# from lib import data_retrieval\n",
    "# from lib.dataset import varDataset\n",
    "from lib.tools import get_climo\n",
    "from lib.tools import get_anomaly\n",
    "from lib.tools import save_ncds\n",
    "from lib.tools import get_running_mean\n",
    "from lib.tools import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a406547a-60e2-4585-bd5e-36e40d2c2300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from global_land_mask import globe\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d4e393-a8f4-4f40-8fb9-385388298641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_window = 7\n",
    "tau1n = 5\n",
    "datebounds = ('1/1','12/31')\n",
    "climoyears = (1979,2017)\n",
    "use_vars = {'T2m':\n",
    "                {'info':('/data/ycheng/JRA/Data/Python','t2m',\n",
    "                                        {'latbounds':(20,74),\n",
    "                                         'lonbounds':(190,305),\n",
    "                                        'datebounds':datebounds,\n",
    "                                        'season0':True,\n",
    "                                        'climoyears':climoyears,\n",
    "                                        'time_window':time_window,\n",
    "                                        'coarsegrain':2.5,\n",
    "                                        'landmask':True})},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c757ad-d985-4de0-9f2a-188caecae1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851f0eb3-411d-4854-ae54-6ad6abc65506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2m\n",
      "/data/ycheng/JRA/Data/Python\n",
      "t2m\n",
      "--> Starting to gather data\n",
      "getting /data/ycheng/JRA/Data/Python/surf_1979.nc\n",
      "2.5\n",
      "[ 90.    88.75  87.5   86.25  85.    83.75  82.5   81.25  80.    78.75\n",
      "  77.5   76.25  75.    73.75  72.5   71.25  70.    68.75  67.5   66.25\n",
      "  65.    63.75  62.5   61.25  60.    58.75  57.5   56.25  55.    53.75\n",
      "  52.5   51.25  50.    48.75  47.5   46.25  45.    43.75  42.5   41.25\n",
      "  40.    38.75  37.5   36.25  35.    33.75  32.5   31.25  30.    28.75\n",
      "  27.5   26.25  25.    23.75  22.5   21.25  20.    18.75  17.5   16.25\n",
      "  15.    13.75  12.5   11.25  10.     8.75   7.5    6.25   5.     3.75\n",
      "   2.5    1.25   0.    -1.25  -2.5   -3.75  -5.    -6.25  -7.5   -8.75\n",
      " -10.   -11.25 -12.5  -13.75 -15.   -16.25 -17.5  -18.75 -20.   -21.25\n",
      " -22.5  -23.75 -25.   -26.25 -27.5  -28.75 -30.   -31.25 -32.5  -33.75\n",
      " -35.   -36.25 -37.5  -38.75 -40.   -41.25 -42.5  -43.75 -45.   -46.25\n",
      " -47.5  -48.75 -50.   -51.25 -52.5  -53.75 -55.   -56.25 -57.5  -58.75\n",
      " -60.   -61.25 -62.5  -63.75 -65.   -66.25 -67.5  -68.75 -70.   -71.25\n",
      " -72.5  -73.75 -75.   -76.25 -77.5  -78.75 -80.   -81.25 -82.5  -83.75\n",
      " -85.   -86.25 -87.5  -88.75 -90.  ]\n",
      "[ -1.25   0.     1.25   2.5    3.75   5.     6.25   7.5    8.75  10.\n",
      "  11.25  12.5   13.75  15.    16.25  17.5   18.75  20.    21.25  22.5\n",
      "  23.75  25.    26.25  27.5   28.75  30.    31.25  32.5   33.75  35.\n",
      "  36.25  37.5   38.75  40.    41.25  42.5   43.75  45.    46.25  47.5\n",
      "  48.75  50.    51.25  52.5   53.75  55.    56.25  57.5   58.75  60.\n",
      "  61.25  62.5   63.75  65.    66.25  67.5   68.75  70.    71.25  72.5\n",
      "  73.75  75.    76.25  77.5   78.75  80.    81.25  82.5   83.75  85.\n",
      "  86.25  87.5   88.75  90.    91.25  92.5   93.75  95.    96.25  97.5\n",
      "  98.75 100.   101.25 102.5  103.75 105.   106.25 107.5  108.75 110.\n",
      " 111.25 112.5  113.75 115.   116.25 117.5  118.75 120.   121.25 122.5\n",
      " 123.75 125.   126.25 127.5  128.75 130.   131.25 132.5  133.75 135.\n",
      " 136.25 137.5  138.75 140.   141.25 142.5  143.75 145.   146.25 147.5\n",
      " 148.75 150.   151.25 152.5  153.75 155.   156.25 157.5  158.75 160.\n",
      " 161.25 162.5  163.75 165.   166.25 167.5  168.75 170.   171.25 172.5\n",
      " 173.75 175.   176.25 177.5  178.75 180.   181.25 182.5  183.75 185.\n",
      " 186.25 187.5  188.75 190.   191.25 192.5  193.75 195.   196.25 197.5\n",
      " 198.75 200.   201.25 202.5  203.75 205.   206.25 207.5  208.75 210.\n",
      " 211.25 212.5  213.75 215.   216.25 217.5  218.75 220.   221.25 222.5\n",
      " 223.75 225.   226.25 227.5  228.75 230.   231.25 232.5  233.75 235.\n",
      " 236.25 237.5  238.75 240.   241.25 242.5  243.75 245.   246.25 247.5\n",
      " 248.75 250.   251.25 252.5  253.75 255.   256.25 257.5  258.75 260.\n",
      " 261.25 262.5  263.75 265.   266.25 267.5  268.75 270.   271.25 272.5\n",
      " 273.75 275.   276.25 277.5  278.75 280.   281.25 282.5  283.75 285.\n",
      " 286.25 287.5  288.75 290.   291.25 292.5  293.75 295.   296.25 297.5\n",
      " 298.75 300.   301.25 302.5  303.75 305.   306.25 307.5  308.75 310.\n",
      " 311.25 312.5  313.75 315.   316.25 317.5  318.75 320.   321.25 322.5\n",
      " 323.75 325.   326.25 327.5  328.75 330.   331.25 332.5  333.75 335.\n",
      " 336.25 337.5  338.75 340.   341.25 342.5  343.75 345.   346.25 347.5\n",
      " 348.75 350.   351.25 352.5  353.75 355.   356.25 357.5 ]\n",
      "rght before coarsegrain\n",
      "2.5\n",
      "coarsegraining\n",
      "[ -1.25   0.     1.25   2.5    3.75   5.     6.25   7.5    8.75  10.\n",
      "  11.25  12.5   13.75  15.    16.25  17.5   18.75  20.    21.25  22.5\n",
      "  23.75  25.    26.25  27.5   28.75  30.    31.25  32.5   33.75  35.\n",
      "  36.25  37.5   38.75  40.    41.25  42.5   43.75  45.    46.25  47.5\n",
      "  48.75  50.    51.25  52.5   53.75  55.    56.25  57.5   58.75  60.\n",
      "  61.25  62.5   63.75  65.    66.25  67.5   68.75  70.    71.25  72.5\n",
      "  73.75  75.    76.25  77.5   78.75  80.    81.25  82.5   83.75  85.\n",
      "  86.25  87.5   88.75  90.    91.25  92.5   93.75  95.    96.25  97.5\n",
      "  98.75 100.   101.25 102.5  103.75 105.   106.25 107.5  108.75 110.\n",
      " 111.25 112.5  113.75 115.   116.25 117.5  118.75 120.   121.25 122.5\n",
      " 123.75 125.   126.25 127.5  128.75 130.   131.25 132.5  133.75 135.\n",
      " 136.25 137.5  138.75 140.   141.25 142.5  143.75 145.   146.25 147.5\n",
      " 148.75 150.   151.25 152.5  153.75 155.   156.25 157.5  158.75 160.\n",
      " 161.25 162.5  163.75 165.   166.25 167.5  168.75 170.   171.25 172.5\n",
      " 173.75 175.   176.25 177.5  178.75 180.   181.25 182.5  183.75 185.\n",
      " 186.25 187.5  188.75 190.   191.25 192.5  193.75 195.   196.25 197.5\n",
      " 198.75 200.   201.25 202.5  203.75 205.   206.25 207.5  208.75 210.\n",
      " 211.25 212.5  213.75 215.   216.25 217.5  218.75 220.   221.25 222.5\n",
      " 223.75 225.   226.25 227.5  228.75 230.   231.25 232.5  233.75 235.\n",
      " 236.25 237.5  238.75 240.   241.25 242.5  243.75 245.   246.25 247.5\n",
      " 248.75 250.   251.25 252.5  253.75 255.   256.25 257.5  258.75 260.\n",
      " 261.25 262.5  263.75 265.   266.25 267.5  268.75 270.   271.25 272.5\n",
      " 273.75 275.   276.25 277.5  278.75 280.   281.25 282.5  283.75 285.\n",
      " 286.25 287.5  288.75 290.   291.25 292.5  293.75 295.   296.25 297.5\n",
      " 298.75 300.   301.25 302.5  303.75 305.   306.25 307.5  308.75 310.\n",
      " 311.25 312.5  313.75 315.   316.25 317.5  318.75 320.   321.25 322.5\n",
      " 323.75 325.   326.25 327.5  328.75 330.   331.25 332.5  333.75 335.\n",
      " 336.25 337.5  338.75 340.   341.25 342.5  343.75 345.   346.25 347.5\n",
      " 348.75 350.   351.25 352.5  353.75 355.   356.25 357.5 ]\n",
      "[90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.\n",
      " 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90. 90.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The points in dimension 1 must be strictly ascending or descending",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2m\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# use_vars[name]['info'][:-1]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43mvarDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43muse_vars\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43muse_vars\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m, in \u001b[0;36mvarDataset.__init__\u001b[0;34m(self, varlabel, datapath, varname, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# print(kwargs)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Concatenate all files into one dataset\u001b[39;00m\n\u001b[1;32m     61\u001b[0m filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([join(datapath, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m listdir(datapath) \\\n\u001b[1;32m     62\u001b[0m              \u001b[38;5;28;01mif\u001b[39;00m isfile(join(datapath, f)) \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m---> 64\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m ds\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m, in \u001b[0;36mvarDataset.get_ds\u001b[0;34m(self, filenames)\u001b[0m\n\u001b[1;32m    200\u001b[0m new_lats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m90\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m91\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarsegrain)\n\u001b[1;32m    201\u001b[0m new_lons \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m360\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarsegrain)\n\u001b[0;32m--> 202\u001b[0m newdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([interp(ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m], new_lats, new_lons, var_day) \u001b[38;5;28;01mfor\u001b[39;00m var_day \u001b[38;5;129;01min\u001b[39;00m newdata])\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# lonres = abs(statistics.mode(np.gradient(ds['lon'].data)[1].flatten()))\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# latres = abs(statistics.mode(np.gradient(ds['lat'].data)[0].flatten()))\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# lonbin = int(self.coarsegrain/lonres)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# new_lons = ds['lon'][::latbin,::lonbin]\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# newdata = newdata[:,::latbin,::lonbin]\u001b[39;00m\n\u001b[1;32m    210\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnew_lats\n",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m new_lats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m90\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m91\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarsegrain)\n\u001b[1;32m    201\u001b[0m new_lons \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m360\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarsegrain)\n\u001b[0;32m--> 202\u001b[0m newdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43minterp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_lats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_lons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_day\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m var_day \u001b[38;5;129;01min\u001b[39;00m newdata])\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# lonres = abs(statistics.mode(np.gradient(ds['lon'].data)[1].flatten()))\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# latres = abs(statistics.mode(np.gradient(ds['lat'].data)[0].flatten()))\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# lonbin = int(self.coarsegrain/lonres)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# new_lons = ds['lon'][::latbin,::lonbin]\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# newdata = newdata[:,::latbin,::lonbin]\u001b[39;00m\n\u001b[1;32m    210\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnew_lats\n",
      "File \u001b[0;32m~/LIM/CPC/run_code/lib/tools.py:59\u001b[0m, in \u001b[0;36minterp\u001b[0;34m(lats, lons, new_lats, new_lons, data_daily)\u001b[0m\n\u001b[1;32m     56\u001b[0m new_lons,new_lats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(new_lons,new_lats)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(lats)\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m interp_interior \u001b[38;5;241m=\u001b[39m \u001b[43mRegularGridInterpolator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlats\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlons\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_daily\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m out \u001b[38;5;241m=\u001b[39m interp_interior((new_lats,new_lons))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/cpc/lib/python3.10/site-packages/scipy/interpolate/_rgi.py:240\u001b[0m, in \u001b[0;36mRegularGridInterpolator.__init__\u001b[0;34m(self, points, values, method, bounds_error, fill_value)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m=\u001b[39m method\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds_error \u001b[38;5;241m=\u001b[39m bounds_error\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_descending_dimensions \u001b[38;5;241m=\u001b[39m \u001b[43m_check_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_values(values)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_dimensionality(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/.conda/envs/cpc/lib/python3.10/site-packages/scipy/interpolate/_rgi.py:27\u001b[0m, in \u001b[0;36m_check_points\u001b[0;34m(points)\u001b[0m\n\u001b[1;32m     25\u001b[0m         p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(p)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe points in dimension \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m must be strictly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascending or descending\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m i)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# see https://github.com/scipy/scipy/issues/17716\u001b[39;00m\n\u001b[1;32m     31\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(p)\n",
      "\u001b[0;31mValueError\u001b[0m: The points in dimension 1 must be strictly ascending or descending"
     ]
    }
   ],
   "source": [
    "name = 'T2m'\n",
    "# use_vars[name]['info'][:-1]\n",
    "out=varDataset(name,*use_vars[name]['info'][:-1],**use_vars[name]['info'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e14f2-6bf6-4446-b51b-e5719b4fd7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

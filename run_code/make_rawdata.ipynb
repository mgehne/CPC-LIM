{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea7a0d6-d8d6-4dc4-bdc1-ab1b4af2bb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class varDataset:\n",
    "\n",
    "    r\"\"\"\n",
    "    Creates an instance of dataset object based on requested files & variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Directory containing files for concatenation.\n",
    "    varname : str\n",
    "        Name of variable in files.\n",
    "    climo : ndarray\n",
    "\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    level : float\n",
    "        If file contains data for multiple levels\n",
    "    climoyears : tuple\n",
    "        (start year, end year) to slice data\n",
    "    latbounds : tuple\n",
    "        (south lat, north lat) to slice data\n",
    "    lonbounds : tuple)\n",
    "        (west lon, east lon) to slice data\n",
    "    eofs : ndarray\n",
    "        Provided eofs\n",
    "    max_eofs : int\n",
    "        How many modes to retain from the EOF decomposition.\n",
    "    time_window : int\n",
    "        Used for running_mean, days.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dataset : object\n",
    "        An instance of Dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,varlabel,datapath,varname,**kwargs):\n",
    "\n",
    "        self.varlabel = varlabel\n",
    "        self.datapath = datapath\n",
    "        self.varname = varname\n",
    "        # kwargs\n",
    "        self.level = kwargs.pop('level',None)\n",
    "        self.climoyears = kwargs.pop('climoyears',None)\n",
    "        self.datebounds = kwargs.pop('datebounds',('1/1','12/31'))\n",
    "        season0 = kwargs.pop('season0',True)\n",
    "        self.latbounds = kwargs.pop('latbounds',None)\n",
    "        self.lonbounds = kwargs.pop('lonbounds',None)\n",
    "        self.time_window = kwargs.pop('time_window',None)\n",
    "        self.climo = kwargs.pop('climo',None)\n",
    "        self.landmask = kwargs.pop('landmask',False)\n",
    "        self.smoother = kwargs.pop('smoother',None)\n",
    "        self.coarsegrain = kwargs.pop('coarsegrain',None)\n",
    "        self.attrs = {}\n",
    "        print(varlabel)\n",
    "        print(datapath)\n",
    "        print(varname)\n",
    "        # print(kwargs)\n",
    "        # Concatenate all files into one dataset\n",
    "        filenames = sorted([join(datapath, f) for f in listdir(datapath) \\\n",
    "                     if isfile(join(datapath, f)) and f.endswith('.nc')])\n",
    "\n",
    "        ds = self.get_ds(filenames)\n",
    "        ds\n",
    "        if self.climoyears is None:\n",
    "            self.climoyears = (min(ds['time']).year,max(ds['time']).year)\n",
    "        climo_set = np.array([(i.year>=min(self.climoyears)) & (i.year<=max(self.climoyears)) for i in ds['time']])\n",
    "        print(self.climoyears)\n",
    "        # print(ds['time'])\n",
    "        # print(climo_set)\n",
    "        ds['time'] = ds['time'][climo_set]\n",
    "        ds['var'] = ds['var'][climo_set]\n",
    "\n",
    "        self.lat = ds['lat'][self.domain]\n",
    "        self.lon = ds['lon'][self.domain]\n",
    "        self.latgrid = ds['lat']\n",
    "        self.longrid = ds['lon']\n",
    "\n",
    "        # Data manipulation\n",
    "        if self.climo is None:\n",
    "            print('getting climo, Line 119 dataset')\n",
    "            self.climo = get_climo(ds['var'],ds['time'],self.climoyears)\n",
    "        else:\n",
    "            print('self.climo is not None')\n",
    "            self.climo = np.array([self.flatten(i) for i in self.climo])\n",
    "            self.climo[abs(self.climo)>1e29]=np.nan\n",
    "\n",
    "        if self.varname == 'anomaly':\n",
    "            print('varname has anomaly')\n",
    "            anomaly = copy.copy(ds['var'])\n",
    "        else:\n",
    "            print('getting anomaly, Line 127 dataset')\n",
    "            anomaly = get_anomaly(ds['var'],ds['time'],self.climo)\n",
    "\n",
    "        if self.time_window is None:\n",
    "            print('no time_window!!!!')\n",
    "            self.running_mean = anomaly\n",
    "        else:\n",
    "            print('getting running mean!!!!')\n",
    "            self.running_mean = get_running_mean(anomaly,self.time_window)[self.time_window:]\n",
    "            ds['time'] = ds['time'][self.time_window:]\n",
    "\n",
    "        if season0:\n",
    "            datewhere = np.where(list(map(self._date_range_test,ds['time'])) & \\\n",
    "                                 (ds['time']>=dt.strptime(f'{min(self.climoyears)}/{self.datebounds[0]}','%Y/%m/%d')) & \\\n",
    "                                 (ds['time']<=dt.strptime(f'{max(self.climoyears)}/{self.datebounds[1]}','%Y/%m/%d')))[0]\n",
    "            print(datewhere)\n",
    "        else:\n",
    "            datewhere = np.where(list(map(self._date_range_test,ds['time'])))[0]\n",
    "\n",
    "        self.time = ds['time'][datewhere]\n",
    "        if isinstance(self.time,np.ma.MaskedArray):\n",
    "            self.time = self.time.data\n",
    "        self.running_mean = self.running_mean[datewhere]\n",
    "\n",
    "        self.climo_stdev = np.nanstd(self.running_mean)\n",
    "        self.climo_mean = np.nanmean(self.running_mean)\n",
    "        print('we are done here')\n",
    "        \n",
    "\n",
    "    def get_ds(self,filenames):\n",
    "\n",
    "        ds = {}\n",
    "        print('--> Starting to gather data')\n",
    "        timer_start = dt.now()\n",
    "        for prog,fname in enumerate(filenames):\n",
    "            print(f'getting {fname}')\n",
    "            ds0 = nc.Dataset(fname)\n",
    "            # print(ds0['time'])\n",
    "            print(self.coarsegrain)\n",
    "\n",
    "            if 'climo' in ds0.variables:\n",
    "                self.climo = ds0['climo']\n",
    "\n",
    "            lat_name = ([s for s in ds0.variables.keys() if 'lat' in s]+[None])[0]\n",
    "            lon_name = ([s for s in ds0.variables.keys() if 'lon' in s]+[None])[0]\n",
    "            lev_name = ([s for s in ds0.variables.keys() if 'lev' in s or 'lv_' in s]+[None])[0]\n",
    "            time_name = ([s for s in ds0.variables.keys() if 'time' in s]+[None])[0]\n",
    "            var_name = self.varname\n",
    "\n",
    "            try:\n",
    "                self.attrs['long_name']=ds0[var_name].long_name\n",
    "            except:\n",
    "                self.attrs['long_name']=None\n",
    "            try:\n",
    "                self.attrs['units']=ds0[var_name].units\n",
    "            except:\n",
    "                self.attrs['units']=None\n",
    "\n",
    "            ds['lat']=ds0[lat_name][:]\n",
    "            ds['lon']=ds0[lon_name][:]\n",
    "            print(ds['lat'])\n",
    "            print(ds['lon'])\n",
    "            if len(ds['lat'].shape)==1:\n",
    "                ds['lon'],ds['lat'] = np.meshgrid(ds['lon'],ds['lat'])\n",
    "            if lev_name is not None:\n",
    "                if self.level is None:\n",
    "                    ilev = 0\n",
    "                else:\n",
    "                    ilev = list(ds0[lev_name]).index(self.level)\n",
    "                    self.attrs['level']=self.level\n",
    "                ds['lev']=ds0[lev_name][:][ilev]\n",
    "            try:\n",
    "                timeunits = ds0[time_name].Units\n",
    "            except:\n",
    "                timeunits = ds0[time_name].units\n",
    "            if timeunits=='Daily':\n",
    "                yr = int(fname[-7:-3])\n",
    "                tmp = np.array([dt(yr,1,1)+timedelta(days=i-1) for i in ds0[time_name][:]])\n",
    "            else:\n",
    "                tmp = nc.num2date(ds0[time_name][:],timeunits,\\\n",
    "                                  only_use_cftime_datetimes=False,only_use_python_datetimes=True)\n",
    "                # print(tmp)\n",
    "            perday = int(86400/(tmp[1]-tmp[0]).total_seconds())\n",
    "            # print(perday)\n",
    "            tmp = tmp[::perday]\n",
    "\n",
    "            if prog==0:\n",
    "                ds['time'] = tmp\n",
    "            else:\n",
    "                ds['time'] = np.append(ds['time'],tmp)\n",
    "\n",
    "            if len(ds0[var_name].shape)>3:\n",
    "                newdata = ds0[var_name][:,ilev].squeeze()\n",
    "            elif len(ds0[var_name].shape)<3:\n",
    "                newdata = ds0[var_name][None,:]\n",
    "            else:\n",
    "                newdata = ds0[var_name][:]\n",
    "\n",
    "            if perday != 1:\n",
    "                newdata = np.apply_along_axis(lambda x: np.convolve(x,np.ones(perday)/perday, mode='valid')[::4],\\\n",
    "                                              axis=0, arr=newdata)\n",
    "\n",
    "            if self.smoother is not None:\n",
    "                newdata = gfilt(newdata,[0]+[self.smoother]*len(newdata.shape[1:]))\n",
    "            print('rght before coarsegrain')\n",
    "            print(self.coarsegrain)\n",
    "            if self.coarsegrain is not None:\n",
    "                print('coarsegraining')\n",
    "                new_lats = np.arange(90,-91,-self.coarsegrain)\n",
    "                new_lons = np.arange(0,360,self.coarsegrain)\n",
    "                newdata = np.array([interp(ds['lat'], ds['lon'], new_lats, new_lons, var_day) for var_day in newdata])\n",
    "                # lonres = abs(statistics.mode(np.gradient(ds['lon'].data)[1].flatten()))\n",
    "                # latres = abs(statistics.mode(np.gradient(ds['lat'].data)[0].flatten()))\n",
    "                # lonbin = int(self.coarsegrain/lonres)\n",
    "                # latbin = int(self.coarsegrain/latres)\n",
    "                # new_lats = ds['lat'][::latbin,::lonbin]\n",
    "                # new_lons = ds['lon'][::latbin,::lonbin]\n",
    "                # newdata = newdata[:,::latbin,::lonbin]\n",
    "                ds['lat']=new_lats\n",
    "                ds['lon']=new_lons\n",
    "            # Move this here so that the interpolation works\n",
    "            ds['lon']=ds['lon'][:]%360\n",
    "            self.mapgrid = np.ones(newdata.shape[1:])*np.nan\n",
    "\n",
    "            if self.latbounds is None:\n",
    "                lim_S = np.amin(ds['lat'])\n",
    "                lim_N = np.amax(ds['lat'])\n",
    "            else:\n",
    "                lim_S = min(self.latbounds)\n",
    "                lim_N = max(self.latbounds)\n",
    "            if self.lonbounds is None:\n",
    "                lim_W = np.amin(ds['lon'])\n",
    "                lim_E = np.amax(ds['lon'])\n",
    "            else:\n",
    "                lim_W = min(self.lonbounds)\n",
    "                lim_E = max(self.lonbounds)\n",
    "            zmask = np.ones(self.mapgrid.shape,dtype=bool)\n",
    "            if self.landmask:\n",
    "                print('maksing')\n",
    "                lon_shift = ds['lon'].copy()\n",
    "                lon_shift[ds['lon']>180] = ds['lon'][ds['lon']>180]-360\n",
    "                zmask = zmask*globe.is_land(ds['lat'],lon_shift)\n",
    "\n",
    "            self.domain = np.where((ds['lat']>=lim_S) & \\\n",
    "                              (ds['lat']<=lim_N) & \\\n",
    "                              (ds['lon']>=lim_W) & \\\n",
    "                              (ds['lon']<=lim_E) & \\\n",
    "                              zmask)\n",
    "\n",
    "            newdata = np.array([n[self.domain] for n in newdata])\n",
    "            newdata[abs(newdata)>1e29]=np.nan\n",
    "\n",
    "            if prog==0:\n",
    "                ds['var'] = newdata\n",
    "            else:\n",
    "                ds['var'] = np.append(ds['var'],newdata,axis=0)\n",
    "        #     update_progress('Gathering data',(prog+1)/len(filenames))\n",
    "        # print('--> Completed gathering data (%.1f seconds)' \\\n",
    "        #       % (dt.now()-timer_start).total_seconds())\n",
    "        return ds\n",
    "    def _date_range_test(self,t):\n",
    "        t_min,t_max = [dt.strptime(i,'%m/%d') for i in self.datebounds]\n",
    "        t_max += timedelta(days=1,seconds=-1)\n",
    "        if t_min<t_max:\n",
    "            test1 = (t>=t_min.replace(year=t.year))\n",
    "            test2 = (t<=t_max.replace(year=t.year))\n",
    "            print(test1,test2)\n",
    "            return test1 & test2\n",
    "        else:\n",
    "            test1 = (t_min.replace(year=t.year)<=t<dt(t.year+1,1,1))\n",
    "            test2 = (dt(t.year,1,1)<=t<=t_max.replace(year=t.year))\n",
    "            return test1 | test2\n",
    "    def regrid(self,a):\n",
    "        # Take 1-d vector of same length as domain\n",
    "        # and transform to original grid\n",
    "        b = self.mapgrid.copy()\n",
    "        b[self.domain] = a\n",
    "        return b\n",
    "        \n",
    "    def save_to_netcdf(self,path,segmentby=None):\n",
    "\n",
    "        data_seg = {}\n",
    "        if segmentby in (None,'all'):\n",
    "            running_mean = self.running_mean\n",
    "            time = self.time\n",
    "            data_seg['all'] = {'running_mean':running_mean,'time':time}\n",
    "\n",
    "        elif segmentby == 'year':\n",
    "            years = np.array([t.year for t in self.time])\n",
    "            for yr in range(min(years),max(years)+1):\n",
    "                idata = np.where(years==yr)\n",
    "                running_mean = self.running_mean[idata]\n",
    "                time = self.time[idata]\n",
    "                data_seg[yr] = {'running_mean':running_mean,'time':time}\n",
    "\n",
    "        try:\n",
    "            attrs = copy.copy(self.attrs)\n",
    "        except:\n",
    "            attrs = {}\n",
    "\n",
    "        for K,V in data_seg.items():\n",
    "            Vmap = list(map(self.regrid,V['running_mean']))\n",
    "            Cmap = list(map(self.regrid,self.climo))\n",
    "            vardict = {\"anomaly\": {'dims':(\"time\",\"lat\",\"lon\"),\n",
    "                                   'data':Vmap,\n",
    "                                   'attrs':attrs},\n",
    "                       \"climo\": {'dims':(\"doy\",\"lat\",\"lon\"),\n",
    "                                 'data':Cmap,\n",
    "                                 'attrs':attrs}\n",
    "                       }\n",
    "            coords={\n",
    "                \"lon\": {'dims':('lon',),'data':self.longrid[0,:],\n",
    "                        'attrs':{'long_name':'longitude','units':'degrees_east'}},\n",
    "                \"lat\": {'dims':('lat',),'data':self.latgrid[:,0],\n",
    "                        'attrs':{'long_name':'latitude','units':'degrees_north'}},\n",
    "                \"time\": {'dims':('time',),'data':V['time'],\n",
    "                         'attrs':{'long_name':'time'}},\n",
    "                \"doy\": {'dims':('doy',),'data':np.arange(1,366),\n",
    "                        'attrs':{'long_name':'day of the year'}},\n",
    "            }\n",
    "            print(f'outputting {self.varlabel} to netcdf, Line 545 dataset.py')\n",
    "            save_ncds(vardict,coords,filename=join(path,f'{self.varlabel}.{K}.nc'))\n",
    "    def flatten(self,a):\n",
    "        # Take n-d array and flatten\n",
    "        b = a[self.domain]\n",
    "        return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e404aae3-f4e7-40d0-85bb-0ec6e54865b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime as dt,timedelta\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdee79c-1b73-4df5-a6a6-46abf81f1b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c06ddce-1d3f-42b7-99cb-273278dfe2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac71cc4-4ef6-4b17-8c2e-b64a4e40db8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lib\n",
    "# from lib import driver\n",
    "# from lib import data_retrieval\n",
    "# from lib.dataset import varDataset\n",
    "from lib.tools import get_climo\n",
    "from lib.tools import get_anomaly\n",
    "from lib.tools import save_ncds\n",
    "from lib.tools import get_running_mean\n",
    "from lib.tools import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a406547a-60e2-4585-bd5e-36e40d2c2300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from global_land_mask import globe\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d4e393-a8f4-4f40-8fb9-385388298641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_window = 7\n",
    "tau1n = 5\n",
    "datebounds = ('1/1','12/31')\n",
    "climoyears = (1979,2017)\n",
    "use_vars = {'T2m':\n",
    "                {'info':('/data/ycheng/JRA/Data/Python','t2m',\n",
    "                                        {'latbounds':(20,74),\n",
    "                                         'lonbounds':(190,305),\n",
    "                                        'datebounds':datebounds,\n",
    "                                        'season0':True,\n",
    "                                        'climoyears':climoyears,\n",
    "                                        'time_window':time_window,\n",
    "                                        'coarsegrain':2.5,\n",
    "                                        'landmask':True})},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c757ad-d985-4de0-9f2a-188caecae1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851f0eb3-411d-4854-ae54-6ad6abc65506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2m\n",
      "/data/ycheng/JRA/Data/Python\n",
      "t2m\n",
      "--> Starting to gather data\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2m\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# use_vars[name]['info'][:-1]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43mvarDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43muse_vars\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43muse_vars\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mvarDataset.__init__\u001b[0;34m(self, varlabel, datapath, varname, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mmin\u001b[39m(ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39myear,\u001b[38;5;28mmax\u001b[39m(ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39myear)\n\u001b[0;32m---> 68\u001b[0m climo_set \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(i\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears)) \u001b[38;5;241m&\u001b[39m (i\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimoyears)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# print(ds['time'])\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(climo_set)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "name = 'T2m'\n",
    "# use_vars[name]['info'][:-1]\n",
    "out=varDataset(name,*use_vars[name]['info'][:-1],**use_vars[name]['info'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b224f-83f7-4508-8efb-f3518c691630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "016e14f2-6bf6-4446-b51b-e5719b4fd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range_test(t):\n",
    "    t_min,t_max = [dt.strptime(i,'%m/%d') for i in ('1/1','12/31')]\n",
    "    t_max += timedelta(days=1,seconds=-1)\n",
    "    # print(f't_max = {t_max}; t_min = {t_min}')\n",
    "    if t_min<t_max:\n",
    "        # print(t_min.replace(year=t.year))\n",
    "        test1 = (t>=t_min.replace(year=t.year))\n",
    "        test2 = (t<=t_max.replace(year=t.year))\n",
    "        # print('option 1')\n",
    "        # print(test1,test2)\n",
    "        return test1 & test2\n",
    "    else:\n",
    "        test1 = (t_min.replace(year=t.year)<=t<dt(t.year+1,1,1))\n",
    "        test2 = (dt(t.year,1,1)<=t<=t_max.replace(year=t.year))\n",
    "        # print('option 2')\n",
    "        # print(test1,test2)\n",
    "        return test1 | test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3e52a73-a31a-4bea-ab4b-d262fcb5515d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt,timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8b0b057-070f-4be5-9438-70d913a9dece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T_START = dt(1979,1,1) #dt(YEAR,MONTH,1)\n",
    "T_END   = dt(1985,12,31) #dt(YEAR,MONTH,LASTDAY)\n",
    "dates = [T_START + timedelta(days=i) for i in range((T_END-T_START).days+1)]\n",
    "# dates\n",
    "# date_objects = [dt(date) for date in dates]\n",
    "climoyears = (1980,1990)\n",
    "datebounds = ('1/1','12/31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "377e6e29-dc8b-4169-b86f-7f7178939bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'list' and 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m datewhere \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(date_range_test,dates))\u001b[38;5;241m&\u001b[39m\\\n\u001b[0;32m----> 2\u001b[0m                                  (\u001b[43mdates\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclimoyears\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatebounds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      3\u001b[0m                      \u001b[38;5;66;03m# & \\\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                                  \u001b[38;5;66;03m# (dates<=dt.strptime(f'{max(climoyears)}/{datebounds[1]}','%Y/%m/%d')))\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'list' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "datewhere = np.where(list(map(date_range_test,dates))&\\\n",
    "                                 (dates>=dt.strptime(f'{min(climoyears)}/{datebounds[0]}','%Y/%m/%d')))\n",
    "                     # & \\\n",
    "                                 # (dates<=dt.strptime(f'{max(climoyears)}/{datebounds[1]}','%Y/%m/%d')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7ff9c83-5132-4404-9556-afb7c3183640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980-01-01 00:00:00\n",
      "1990-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(dt.strptime(f'{min(climoyears)}/{datebounds[0]}','%Y/%m/%d'))\n",
    "print(dt.strptime(f'{max(climoyears)}/{datebounds[1]}','%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91fa9b-3872-4735-8e14-15d4fd1e34ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
